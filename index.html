<!DOCTYPE html>
<html lang="en">
<head>
<title>myweb</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="style2.css">
<style>
body,h1,h2,h3,h4,h5 {font-family: "Poppins", sans-serif}
body {font-size:16px;}
.w3-half img{margin-bottom:-6px;margin-top:16px;opacity:0.8;cursor:pointer}
.w3-half img:hover{opacity:1}
</style>
</head>
<body>

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-red w3-collapse w3-top w3-large w3-padding" style="z-index:3;width:300px;font-weight:bold;" id="mySidebar"><br>
  <a href="javascript:void(0)" onclick="w3_close()" class="w3-button w3-hide-large w3-display-topleft" style="width:100%;font-size:22px">Close Menu</a>
  <div class="w3-container">
    <h3 class="w3-padding-64"><b>CS1102<br>Course Project - 2023/2024 Semester B</b></h3>
  <p>Li Tik Bond Douglas 56622926</p>
    <p>Chan Wing Chung 56616540</p>
    <p>Cheung Sze Wan 57159900</p>
    <p>Wong Kai Hei 57151949</p>
  </div>
  <div class="w3-bar-block">
    <a href="#" onclick="w3_close()" class="w3-bar-item w3-button w3-hover-white">Home</a> 
    <a href="#Introduction" onclick="w3_close()" class="w3-bar-item w3-button w3-hover-white">Introduction</a> 
    <a href="#Pros" onclick="w3_close()" class="w3-bar-item w3-button w3-hover-white">Pros</a> 
    <a href="#Cons" onclick="w3_close()" class="w3-bar-item w3-button w3-hover-white">Cons</a> 
    <a href="#Limitation" onclick="w3_close()" class="w3-bar-item w3-button w3-hover-white">Limitation</a> 
    <a href="#Referencelist" onclick="w3_close()" class="w3-bar-item w3-button w3-hover-white">Reference Lists</a> 
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-container w3-top w3-hide-large w3-red w3-xlarge w3-padding">
  <a href="javascript:void(0)" class="w3-button w3-red w3-margin-right" onclick="w3_open()">☰</a>
  <span>CS1102</span>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:340px;margin-right:40px">

  <!-- Header -->
  <div class="w3-container" style="margin-top:80px" id="Introduction">
    <h1 class="w3-jumbo"><b>The pros and cons of Large Language Models (LLMs)
	    <img src="https://github.com/acxianren/CS1102prj/blob/main/openai-logo.png?raw=true" width="200" height="200">
    </b></h1>
    <h1 class="w3-xxxlarge w3-text-red"><b>Introduction-History & Architecture</b></h1>
    <hr style="width:50px;border:5px solid red" class="w3-round">
  </div>
<h2>History</h2>
     <p>
      In 1950, the foundation of LLM was used for doing the experiments with neural networks and neural information processing systems, which allowed it to deal with natural language. That foundation is used to auto translate from Russian to English.
    </p>
    <p>
      In 1960, the first idea of LLM, Eliza, was created by MIT researcher Joseph Weizenbaum. At that time, Eliza was the first chatbot in the world. The creation of it has increased people’s attention in the area of natural language processing and LLM.
    </p>
    <p>
      In 1997, Long short-term memory (LSTM) network was created. The difference between LSTM and the model before this is that LSTM can address the vanishing gradient problem. This allows LSTM to capture and preserve important dependencies because it can selectively remember or forget information over long sequences.
    </p>
    <p>
      IN 2018, BERT (Bidirectional Encoder Representations from Transformers) was invented, which model uses the revolutionary structure called Transformer. The Transformer structure can predict the following context of each word and do tokenization simultaneously. This approach allows BERT to have a deeper understanding of the context and the meaning of the words.
    </p>
    <p>
      In 2020, this is the era of GPT (Generative Pre-trained Transformer) which was released by OpenAI. GPT is one of the most powerful LLM. For GPT-1, it only has 117 millions parameters for the model. For GPT-2, it has 1.5 billion parameters. For GPT-3, the number of parameters has increased to 175 billion. For the recent one GPT-5, it has 1.76 trillion parameters. The huge amount of parameters allow GPT to have strong ability for perform a wide range of language tasks, including text generation, translation, summarization, and question answering.
    </p>
<h2>Architecture</h2>
    <p>
     To understand LLM, it is necessary to understand the structure of Transformer. Before Transformers is invented, the main structure of LLM is Recurrent neural network (RNN), RNN deal with the input according to the sequence of the input, output of every step depends on the the hidden status of before and input of now, and the new calculation needs to wait for the finish of last step. It causes the efficiency of training to be relatively low. Move rover, RNN is not good at dealing with long sequences of input and long context. Due to the structure of RNN, the longer the input is, the smaller the front context affects the context at the back. Therefore, it is hard for RNN to capture the relationship between words in a long sentence. But in natural language, it is normal to have information depending on a long distance. Although there is LSTM to address this kind of long sequences problem, it still faces the problem of inability to concurrent computing.
    </p>
    <p>
      To solve the problem mentioned above, a transfer structure has been created. It has the ability of learning dependencies of all input sequences. It will not be affected by the short memory. The attention mechanism is the reason why transformers can have those features. While dealing with the word from the input in transformers, it not only concerns the word itself, but transformers will also concern all the other words in the input sequences and give every word weight of attention. Weight of attention is learned while the model is training step by step. Therefore, transformers can know the dependencies between the word dealing with and other words in the input, and thus focus on the important part of the context. Although the distance between two words is far, transformers can still capture the dependencies between two words.
    </p>
    <p>
     Another feature of the transformer is positional encoding, which can help the model to process the input sequences in parallel, meaning that it does not need to consider the order of input sequences. In Transformer, every word in the input sequences will be embedded into the word vector, and the positional vector before entering them into the neural network. This transformation can help the model understand the meaning of each word and capture the position of each word in the sentence. Word can input different sequences while using a transformer. Model can process all the positions of the input sequences at the same time. It doesn’t need to process according to the order of the input as RNN does. Every input of the Transformer model can do the calculation separately, and don’t need to wait for the result of another word. It increases the efficiency of model training. Therefore, huge models are relatively easy to train using transformers. 
    </p>	

  <!-- Pros -->
  <div class="w3-container" id="Pros" style="margin-top:75px">
    <h1 class="w3-xxxlarge w3-text-red"><b>Pros</b></h1>
    <hr style="width:50px;border:5px solid red" class="w3-round">
    <h2>Help in content creation</h2>
    <p>
     LLM collected vast amounts of data from basically everywhere. Recently, so many tools have helped people to create various content in a much faster way than ever before. Including stories, summarization, subtitles, or even academic essays. In the past, when someone needed to write paragraphs about a specific topic, they needed to use a lot of time to find references and process that information to write their words and understand the topics. 
    </p>
    <p>
     However, after the popularization of LLM, everything changed. People can enter keywords of the topics, and LLM will give you the information you need almost instantly which is already summarized. Moreover, is can also assist in checking grammatical mistakes and typos for better writing (Kasneci et al., 2023). Therefore, when creating content, LLM can provide us with an integrated outline and information about the topics, which can help people brainstorm and offer an example to refer to in a short period of time. For example, after we enter the keywords, LLM can generate a large number of viewpoints and perspectives on an essay topic for brainstorming or extending the content of a story automatically for us when we lack inspiration.
    </p>
    <h2>Knowledge learning and exploring</h2>
    <p>
     LLM is like an upgraded version of the encyclopedia. It knows everything we know, and everything we do not know. In terms of the quantity of knowledge, humans can not even be qualified to compete with LLM and it is not even close. In daily life, when people are confused about a topic or a weird question in their mind, they usually cannot find a person who knows the answer. When they are searching for the answer on the Internet, the answer may not be integrated and it may be too lengthy or complicated for a person without knowledge about that aspect. This might have stopped and blocked the imagination and curiosity toward knowledge of people so many times in the past. 
    </p>
    <p>
     For now, with the help of LLM, we can ask the questions we are curious about to LLM anywhere at any time. LLM can provide us with integrated answers. For those who have further questions, they can ask instantly and LLM will keep answering based on the previous questions and information. It is very convenient for people to learn something deeply and familiar with a topic. For children, it can also enhance their curiosity to their questions and confusion (Abdelghani et al., 2023). Before the invention of LLM, people had to ask a real person with the relevant knowledge to obtain a similar effect, which was difficult to find and would waste others’ time. In my personal experience, when I was having problems understanding the lecturer and the slides in some lessons, I could simply ask the point I got confused about the topics further and further to LLM until I fully understood the concept, which is much more efficient than searching the answers by ourselves or finding someone who is capable to teach us.
    </p>
    <section>
    <h2>Lower the threshold of professional skills</h2>
    <p>
     Coding is usually known as a very professional and difficult skill in public cognition. In fact, most people do not have knowledge about programming or other basic knowledge of various professional aspects. For the public who try to solve a question above their education level or out of their knowledge area, it may take tons of time to learn about the basic concepts and principles first for them to even have a sense of what the questions are asking for. But with the help of LLM, people can simply throw the problems or questions to the LLM, and LLM can provide them with a framework or process on how to solve the problem or even the answer (Austin et al., 2021). Usually, a person without related knowledge cannot even understand the questions. However, with the help of LLM, those people can have access and a chance to finish the questions. Although the answer may not be correct, it provides an opportunity for people to take a big step on the question instead of learning from the very beginning. By combining the pros of knowledge exploration previously mentioned, they might even be able to solve some easy problems.
    </p>	
  </div>
  
 <!-- Cons -->
  <div class="w3-container" id="Cons" style="margin-top:75px">
    <h1 class="w3-xxxlarge w3-text-red"><b>Cons</b></h1>
    <hr style="width:50px;border:5px solid red" class="w3-round">
  <h2>Ethical problem</h2>
  <p>As a LLM model, it can generate a large amount of content in a short time. But at the same time, when that content is generated, the process of accessing data may damage intellectual property rights, as the data does not have the consent of the original author to copy and use it, and the reference from which the data was obtained will not be shown. Moverover, If the user is a student and uses the generated data for academic purposes without modifying it, it will not only reduce the student's learning effectiveness and imagination, but may also lead to academic plagiarism. </p>
  <p>Besides, the concerns about malicious use are raised . LLM can easily produce a large amount of seemingly credible fake news. When these news are widespread in society, they may cause panic among the public. Moreover,  LLM also has the ability to imitate the texts of individuals and organizations, which may be used by scammers for illegal purposes such as fraud, and affecting social stability.</p>
  <h2>Low accuracy and reliability</h2>
  <p>The other cons for LLM is the low accuracy and reliability of the model. LLM has an impressive advancement in natural language processing, like GPT-4, but the output and the content LLM generated are still not 100% accurate.</p>
  <p>The accuracy and reliability of LLM are affected by many factors. As we know LLM are highly rely on the training data during the learning phase. For example, if the training data contain error , bias or misleading information, LLM will learn and generate some wrong or misleading content due to the wrong training data. Also, as the society and the dynamic nature of language are evolving at an extremely fast speed, the new information, trends, and data  may not be contained or updated in the training data of LLM, which causes the content generated to be outdated, and having a rather low reliability.</p>
  <h2>Privacy concern</h2>
  <p>LLM also raises significant privacy concerns.  When interacting with  LLM, users often need to provide personal information, like name and personal status, even including sensitive topics. There is a concern of the private information being revealed, and this kind of concern will be more serious when users are using LLM for legal and healthcare consulting, as the exchanged information is extremely private and sensitive.</p>
  <p>Therefore, LLM should have a better security system and encryption, in order to protect user privacy, and should allow users to delete the saving of the user data and history, or allow users  to use LLM as anonymous , to decrease the chance of data reveal , and increase user confidence in using LLM. </p>
  </div>


  <!-- Limitation -->
<div class="w3-container" id="Limitation" style="margin-top:75px">
    <h1 class="w3-xxxlarge w3-text-red"><b>Limitation</b></h1>
    <hr style="width:50px;border:5px solid red" class="w3-round">
    <p>Although LLM has a variety of pros and cons to users, we should take advantage of it while understanding its limitations to be well-adapted in our application of reality. Fairness, trustworthiness and safety are essential conditions to evaluate and measure LLM and its output. Since training LLM requires high investment of money, time, technical resources, human capital and data parameters, only few organizations/ firms can afford it and launch it to the public. There are three famous LLM with specific features: Generative Pre-trained Transformer (GPT) developed by OpenAI, Language Model for Many Applications (LLaMA) created by Meta and BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) developed by Hugging Face.</p>
    <p>GPT is professional in generating natural language content and succeeds in producing rational and logically significant regular language text in view of a given brief. Best utilization in text rewriting, experimental writing help and dialogue creation. LLaMA is intended to deal with different normal language handling (NLP) issues, including text age, grouping, question addressing, and rundown. Specially professional in versatility in Normal Language Handling (NLP) tasks, an open-source allowing users customized with high adaptability. BLOOM is capable in multilingual capacities which makes it reasonable for multilingual languages. Because of its advanced machine learning algorithms, AI calculations and large number of training datasets, it leads to a high precision and reliability outcome in comprehend and producing text. LLaMA and BLOOM are open-source models to the public.</p>
    <h2>(1)LLM internal limitation: Absence of common sense, judgment thinking and bias enhancement</h2>
    <p>As different LLMs, GPT may display an absence of common sense reasoning and judgment thinking, and implies it might battle to create reactions that line up with regular information and setting. Moreover, GPT is likewise susceptible to bias amplification. The powerless to predisposition intensification is assuming the training data contains one-sided or biased insight. GPT might output reactions that support orientation generalizations or display the opposite orientation inclination in the text response inadvertently. This limitation is caused by bias amplification of dataset training periods if the bias can impact outcome to damage the society stabilization implied by Levy,S. Gabriel (2023) research "large language model would show social biases and create misinformation because of training on harmful data sets potentially." LLM's inaccuracy and potential predisposition are the limitations that affect the output of fairness, trustworthiness and safety with impacting user mindset and judgment. Furthermore, it may leads to ethical concerns for the inaccuracy response.</p>
    <h2>(2)Users’ limitation: Lack of thinking transparency and time-sensitive</h2>
    <p>Take BLOOM for instance, the professional architecture, training methodologies, and datasets used to train BLOOM are closely guarded, limiting users' understanding of the model's inner workings. Due to the lack of transparency in LLMs, characterized by their complex and opaque nature resembling "black boxes," it becomes challenging to track the reasoning process, hindering the comprehension of decision-making and predictions mentioned by Liao, Q. V. (2023). Lack of transparency in BLOOM with its  exceptionally intricacy of billions of parameters and intricate interactions between its layers make it challenging to trace the decision-making process and thinking process. Users have difficulty interpreting BLOOM's learned patterns and representations. LLMs are trained on specific parameters and large databases based on information available up until 2021(a cutoff date for the model data collected). After that, the output generated by LLM may lack up-to-date information sources or lead to missing or failing to consider recent situations. The time coverage is limited to not time-sensitive scenarios. (For example GPT and LLaMA data source is limited to 2021 and 2023) It is also limited to responses on financial investment and stock market time-sensitive questions.
</p>
    <h2>(3)LLM output limitation: low effectiveness of fine-tuning as user-based</h2> 
    <p>LLM is designed with fixed datasets, and functional formal or keyword weighting understanding adjustment. Although user preferences are different a LLM is difficult to adjust and fine-tuning to match users' expectations and must require huge amount of substantial resources. Previous research has emphasized the benefits of fine-tuning LLMs; however, this practice can be computationally expensive, rendering it unfeasible in resource-limited settings, especially for models with billions of parameters. (Weyssow, Kim, Zhou, Lo, & Sahraoui, 2024)In another word, it is low viability of calibrating as a constraint to LLM yield. Also, the content moderated is restricted too. To protect different users' groups and sure the appropriate content that avoids violent, discriminatory language and fake news. LLM implementing effective strategies to filtering and flagging content.</p>
	</div>

<!-- ReferenceLists -->
 <div class="w3-container" id="Referencelist" style="margin-top:75px">
<h1 class="w3-xxxlarge w3-text-red"><b>Reference Lists</b></h1>
    <hr style="width:50px;border:5px solid red" class="w3-round">
<p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł., and Polosukhin, I. (2017). "Attention Is All You Need." In Proceedings of the 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. Retrieved from: https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</p>
<p>Toloka Team. (2023, June 26). The history, timeline, and future of LLMs. Retrieved from https://toloka.ai/blog/history-of-llms/</p>
<p>
Kasneci, E., Sessler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., Günnemann, S., Hüllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, O., Sailer, M., Schmidt, A., Seidel, T., . . . Kasneci, G. (2023). ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 103, 102274. https://doi.org/10.1016/j.lindif.2023.102274</p>
<p>Abdelghani, R., Wang, Y., Yuan, X., Wang, T., Lucas, P., Sauzéon, H., & Oudeyer, P. (2023c). GPT-3-Driven Pedagogical Agents to train children’s Curious Question-Asking skills. International Journal of Artificial Intelligence in Education. https://doi.org/10.1007/s40593-023-00340-7
</p>
<p>Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski,H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., Sutton, C. (2021). Program Synthesis with Large Language Models. arXiv. https://arxiv.org/pdf/2108.07732.pdf</p>
<p>Raymond, D. (2023, November 25). Top 10 cons & disadvantages of large language models (LLM). ProjectManagers.net. https://projectmanagers.net/top-10-disadvantages-of-large-language-models-llm/ 
</p>
<p>Weyssow, M., Kim, K., Zhou, X., Lo, D., & Sahraoui, H. (2024, January 18). Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models. 
https://arxiv.org/html/2308.10462v2
</p>
<p>Liao, Q. V. (2023). AI Transparency in the Age of Large Language Models: A Human-Centered Research Roadmap. https://medium.com/human-centered-ai/ai-transparency-in-the-age-of-large-language-models-a-human-centered-research-roadmap-19bd3a55914a
</p>
<p>Levy, S. Gabriel. (2023). Responsible AI via Responsible Large Language Models. Thesis (Ph.D.)--University of California, Santa Barbara, 2023.
file:///Users/szewancheung/Downloads/[30529918]%20Responsible_AI_via_Responsible_Large_Language_Models.pdf
</p>
</div>
<!-- End page content -->
</div>

<!-- W3.CSS Container -->
<div class="w3-light-grey w3-container w3-padding-32" style="margin-top:75px;padding-right:58px"><p class="w3-right"> 

<script>
// Script to open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}

// Modal Image Gallery
function onClick(element) {
  document.getElementById("img01").src = element.src;
  document.getElementById("modal01").style.display = "block";
  var captionText = document.getElementById("caption");
  captionText.innerHTML = element.alt;
}
</script>

</body>
</html>
